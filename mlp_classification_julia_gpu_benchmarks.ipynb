{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptron Classification on GPU with Julia\n",
    "====\n",
    "\n",
    "**Algorithm:** Multi-layer perceptron neural network classifier with the [Flux](https://github.com/FluxML) ML library\n",
    "\n",
    "**Task:** Compare loss and accuracy of the algorithm over epochs on different computing platforms, using CPUs or GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro bash_str(s) open(`bash`,\"w\",stdout) do io; print(io, s); end; end; # this creates a bash macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to create, train and benchmark a MLP NN\n",
    "---\n",
    "\n",
    "### Code below modified from [FluxML/model-zoo](https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl).\n",
    "\n",
    "This version will run on CPU because we are not ```using CuArrays```, meaning the ```|> gpu``` will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module MLPClassifier\n",
    "\n",
    "    using Flux, Statistics\n",
    "    using Flux: onehotbatch, onecold, crossentropy, throttle # Flux is a neural network machine learning library, rivals TensorFlow\n",
    "    using Base.Iterators: repeated\n",
    "#     using CuArrays\n",
    "\n",
    "    function create_model()\n",
    "        \n",
    "        m = Chain(Dense(28^2, 32, relu), Dense(32, 10), softmax) |> gpu\n",
    "        return m\n",
    "    \n",
    "    end\n",
    "\n",
    "    function benchmark_model(m, imgs, labels; epochs=3, dataset_n=1)\n",
    "\n",
    "        # Stack images into one large batch. Concatenates along 2 dimensions\n",
    "        X = hcat(float.(reshape.(imgs, :))...) |> gpu # pipe to gpu, this does nothing when CuArrays is not loaded\n",
    "\n",
    "        # One-hot-encode the labels\n",
    "        Y = onehotbatch(labels, 0:9) |> gpu     \n",
    "\n",
    "        loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "        accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "        # Create a dataset by repeating dataset_n times\n",
    "        dataset = repeated((X, Y), dataset_n)\n",
    "\n",
    "        # accuracy() computes the fraction of correctly predicted outcomes in outputs (Y) according to the given true targets (X).\n",
    "        # loss() the loss function gives a number which an optimization would seek to minimize\n",
    "\n",
    "        opt = ADAM()\n",
    "\n",
    "        # Train the multi-layer-perceptron:\n",
    "        start_time = time_ns()\n",
    "        for i = 1:epochs\n",
    "            Flux.train!(loss, params(m), dataset, opt)\n",
    "        end\n",
    "        end_time = time_ns()\n",
    "\n",
    "        # Results\n",
    "        training_time = (end_time - start_time)/1.0e9 #seconds\n",
    "        loss_result = loss(X, Y)\n",
    "        accuracy_result = accuracy(X, Y)\n",
    "\n",
    "        # Create results dictionary and print to output\n",
    "        output_dict = Dict(\"training_time\" => training_time, \"loss_result\" => loss_result, \"accuracy_result\" => accuracy_result)\n",
    "        return output_dict\n",
    "\n",
    "    end\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"mlp.jl\", In[IJulia.n-1]); # write the previously run cell to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model and benchmark functions work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, NNlib.relu), Dense(32, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux.Data.MNIST # MNIST digits\n",
    "model = MLPClassifier.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Real} with 3 entries:\n",
       "  \"accuracy_result\" => 0.140633\n",
       "  \"training_time\"   => 5.8175\n",
       "  \"loss_result\"     => 2.24282 (tracked)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.MLPClassifier.benchmark_model(model, MNIST.images(), MNIST.labels(), epochs=2, dataset_n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a script to run benchmarks of the model\n",
    "----\n",
    "\n",
    "Here we get the median result for the benchmarks from multiple ```repeats```, then print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{String,Real}("
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module MLPClassifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"accuracy_result\"=>0.15815,\"training_time\"=>0.455815,\"loss_result\"=>2.28231 (tracked))"
     ]
    }
   ],
   "source": [
    "include(\"./mlp.jl\")\n",
    "using Main.MLPClassifier\n",
    "using Statistics\n",
    "using Flux.Data.MNIST\n",
    "\n",
    "# Get benchmarking paramaters:\n",
    "repeats = 3 # defaults\n",
    "epochs = 1\n",
    "dataset_n = 1\n",
    "\n",
    "if length(ARGS) == 3 # replace parameters with command line args when provided\n",
    "\n",
    "    repeats = parse(Int64, ARGS[1])\n",
    "    epochs = parse(Int64, ARGS[2])\n",
    "    dataset_n = parse(Int64, ARGS[3])\n",
    "    \n",
    "end\n",
    "\n",
    "# Create model:\n",
    "model = MLPClassifier.create_model()\n",
    "\n",
    "# Benchmark the model:\n",
    "accuracy_results = []\n",
    "training_times = []\n",
    "loss_results = []\n",
    "\n",
    "imgs = MNIST.images()\n",
    "labels = MNIST.labels()\n",
    "\n",
    "for i = 1:repeats\n",
    "    benchmarks = Main.MLPClassifier.benchmark_model(model, imgs, labels, epochs=epochs, dataset_n=dataset_n)\n",
    "    append!(accuracy_results, benchmarks[\"accuracy_result\"])\n",
    "    append!(training_times, benchmarks[\"training_time\"])\n",
    "    append!(loss_results, benchmarks[\"loss_result\"])\n",
    "end\n",
    "\n",
    "# Print benchmarks\n",
    "print(Dict(\"training_time\" => median(training_times), \"loss_result\" => median(loss_results), \"accuracy_result\" => median(accuracy_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1011"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"iterate_benchmarks.jl\", In[IJulia.n-1]) # write the previously run cell to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Docker container running the benchmarks and push to Docker Hub\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dockerfile\n",
    "\n",
    "I use a CUDA base image that will allow for GPU functionality. For now, I refrain from installing the ```CuArrays``` Julia package.\n",
    "\n",
    "I have set the benchmarks to take command line arguments which can be changed when we run the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"nvidia\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"nvidia\" after end of expression",
      ""
     ]
    }
   ],
   "source": [
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN  apt-get update \\\n",
    "  && apt-get install -y wget \\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "\n",
    "RUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\n",
    "RUN tar xvfa julia-1.0.0-linux-x86_64.tar.gz\n",
    "\n",
    "COPY mlp.jl /julia-1.0.0/bin/mlp.jl\n",
    "COPY iterate_benchmarks.jl /julia-1.0.0/bin/iterate_benchmarks.jl\n",
    "\n",
    "WORKDIR /julia-1.0.0/bin\n",
    "RUN ./julia -e 'using Pkg; Pkg.add(\"Flux\")'\n",
    "# RUN ./julia -e 'using Pkg; Pkg.add(\"CuArrays\")'\n",
    "CMD ./julia iterate_benchmarks.jl 1 1 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"Dockerfile\", In[IJulia.n-1]) # write the previously run cell to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build #1\n",
    "Lets tag this build as ```cpu``` since we are not using ```CuArrays```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  155.6kB\n",
      "Step 1/11 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> f722eab170b7\n",
      "Step 2/11 : RUN  apt-get update   && apt-get install -y wget   && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 6c8df59a2db7\n",
      "Step 3/11 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 52daa6d5e08f\n",
      "Step 4/11 : RUN apt-get -y install curl\n",
      " ---> Using cache\n",
      " ---> f4b4ff210f19\n",
      "Step 5/11 : RUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\n",
      " ---> Using cache\n",
      " ---> 9b5d7c5c2cfd\n",
      "Step 6/11 : RUN tar xvfa julia-1.0.0-linux-x86_64.tar.gz\n",
      " ---> Using cache\n",
      " ---> 71f8c0aebc04\n",
      "Step 7/11 : COPY mlp.jl /julia-1.0.0/bin/mlp.jl\n",
      " ---> dbc821396ac6\n",
      "Step 8/11 : COPY iterate_benchmarks.jl /julia-1.0.0/bin/iterate_benchmarks.jl\n",
      " ---> 9565297b2e16\n",
      "Step 9/11 : WORKDIR /julia-1.0.0/bin\n",
      " ---> Running in e7fbe7fd4f01\n",
      "Removing intermediate container e7fbe7fd4f01\n",
      " ---> b961383779f7\n",
      "Step 10/11 : RUN ./julia -e 'using Pkg; Pkg.add(\"Flux\")'\n",
      " ---> Running in 5f444479957c\n",
      "   Cloning default registries into /root/.julia/registries\n",
      "   Cloning registry General from \"https://github.com/JuliaRegistries/General.git\"\n",
      "\u001b[2K\u001b[?25h  Updating registry at `~/.julia/registries/General`2 %0.0 %\n",
      "  Updating git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h Resolving package versions...\n",
      " Installed DiffRules ──────────── v0.0.10\n",
      " Installed CSTParser ──────────── v0.5.2\n",
      " Installed MacroTools ─────────── v0.5.0\n",
      " Installed BinaryProvider ─────── v0.5.3\n",
      " Installed DataStructures ─────── v0.15.0\n",
      " Installed Flux ───────────────── v0.8.2\n",
      " Installed Adapt ──────────────── v0.4.2\n",
      " Installed Colors ─────────────── v0.9.5\n",
      " Installed Media ──────────────── v0.5.0\n",
      " Installed NNlib ──────────────── v0.5.0\n",
      " Installed ZipFile ────────────── v0.8.1\n",
      " Installed CodecZlib ──────────── v0.5.2\n",
      " Installed FixedPointNumbers ──── v0.5.3\n",
      " Installed Requires ───────────── v0.5.2\n",
      " Installed Compat ─────────────── v2.1.0\n",
      " Installed URIParser ──────────── v0.4.0\n",
      " Installed Missings ───────────── v0.4.0\n",
      " Installed ForwardDiff ────────── v0.10.3\n",
      " Installed SortingAlgorithms ──── v0.3.1\n",
      " Installed DiffResults ────────── v0.0.4\n",
      " Installed CommonSubexpressions ─ v0.2.0\n",
      " Installed Tracker ────────────── v0.1.0\n",
      " Installed NaNMath ────────────── v0.3.2\n",
      " Installed Tokenize ───────────── v0.5.3\n",
      " Installed Reexport ───────────── v0.2.0\n",
      " Installed Juno ───────────────── v0.7.0\n",
      " Installed SpecialFunctions ───── v0.7.2\n",
      " Installed ColorTypes ─────────── v0.7.5\n",
      " Installed AbstractTrees ──────── v0.2.1\n",
      " Installed TranscodingStreams ─── v0.9.3\n",
      " Installed StatsBase ──────────── v0.29.0\n",
      " Installed BinDeps ────────────── v0.8.10\n",
      " Installed OrderedCollections ─── v1.0.2\n",
      " Installed StaticArrays ───────── v0.10.3\n",
      "  Updating `~/.julia/environments/v1.0/Project.toml`\n",
      "  [587475ba] + Flux v0.8.2\n",
      "  Updating `~/.julia/environments/v1.0/Manifest.toml`\n",
      "  [1520ce14] + AbstractTrees v0.2.1\n",
      "  [79e6a3ab] + Adapt v0.4.2\n",
      "  [9e28174c] + BinDeps v0.8.10\n",
      "  [b99e7846] + BinaryProvider v0.5.3\n",
      "  [00ebfdb7] + CSTParser v0.5.2\n",
      "  [944b1d66] + CodecZlib v0.5.2\n",
      "  [3da002f7] + ColorTypes v0.7.5\n",
      "  [5ae59095] + Colors v0.9.5\n",
      "  [bbf7d656] + CommonSubexpressions v0.2.0\n",
      "  [34da2185] + Compat v2.1.0\n",
      "  [864edb3b] + DataStructures v0.15.0\n",
      "  [163ba53b] + DiffResults v0.0.4\n",
      "  [b552c78f] + DiffRules v0.0.10\n",
      "  [53c48c17] + FixedPointNumbers v0.5.3\n",
      "  [587475ba] + Flux v0.8.2\n",
      "  [f6369f11] + ForwardDiff v0.10.3\n",
      "  [e5e0dc1b] + Juno v0.7.0\n",
      "  [1914dd2f] + MacroTools v0.5.0\n",
      "  [e89f7d12] + Media v0.5.0\n",
      "  [e1d29d7a] + Missings v0.4.0\n",
      "  [872c559c] + NNlib v0.5.0\n",
      "  [77ba4419] + NaNMath v0.3.2\n",
      "  [bac558e1] + OrderedCollections v1.0.2\n",
      "  [189a3867] + Reexport v0.2.0\n",
      "  [ae029012] + Requires v0.5.2\n",
      "  [a2af1166] + SortingAlgorithms v0.3.1\n",
      "  [276daf66] + SpecialFunctions v0.7.2\n",
      "  [90137ffa] + StaticArrays v0.10.3\n",
      "  [2913bbd2] + StatsBase v0.29.0\n",
      "  [0796e94c] + Tokenize v0.5.3\n",
      "  [9f7883ad] + Tracker v0.1.0\n",
      "  [3bb67fe8] + TranscodingStreams v0.9.3\n",
      "  [30578b45] + URIParser v0.4.0\n",
      "  [a5390f91] + ZipFile v0.8.1\n",
      "  [2a0f44e3] + Base64 \n",
      "  [ade2ca70] + Dates \n",
      "  [8bb1440f] + DelimitedFiles \n",
      "  [8ba89e20] + Distributed \n",
      "  [b77e0a4c] + InteractiveUtils \n",
      "  [76f85450] + LibGit2 \n",
      "  [8f399da3] + Libdl \n",
      "  [37e2e46d] + LinearAlgebra \n",
      "  [56ddb016] + Logging \n",
      "  [d6f4376e] + Markdown \n",
      "  [a63ad114] + Mmap \n",
      "  [44cfe95a] + Pkg \n",
      "  [de0858da] + Printf \n",
      "  [9abbd945] + Profile \n",
      "  [3fa0cd96] + REPL \n",
      "  [9a3f8284] + Random \n",
      "  [ea8e919c] + SHA \n",
      "  [9e88b42a] + Serialization \n",
      "  [1a1011a3] + SharedArrays \n",
      "  [6462fe0b] + Sockets \n",
      "  [2f01184e] + SparseArrays \n",
      "  [10745b16] + Statistics \n",
      "  [8dfed614] + Test \n",
      "  [cf7118a7] + UUIDs \n",
      "  [4ec0a83e] + Unicode \n",
      "  Building ZipFile ─────────→ `~/.julia/packages/ZipFile/YHTbb/deps/build.log`\n",
      "  Building CodecZlib ───────→ `~/.julia/packages/CodecZlib/9jDi1/deps/build.log`\n",
      "  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/fvheQ/deps/build.log`\n",
      "Removing intermediate container 5f444479957c\n",
      " ---> 4e94c0356a83\n",
      "Step 11/11 : CMD ./julia iterate_benchmarks.jl 1 1 1\n",
      " ---> Running in 09bf55be809a\n",
      "Removing intermediate container 09bf55be809a\n",
      " ---> 760996b36a7c\n",
      "Successfully built 760996b36a7c\n",
      "Successfully tagged edwardchalstrey/mlp_classifier:cpu\n"
     ]
    }
   ],
   "source": [
    "bash\"\"\"\n",
    "docker build -t edwardchalstrey/mlp_classifier:cpu .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check we can run the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Downloading MNIST dataset\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   469  100   469    0     0    174      0  0:00:02  0:00:02 --:--:--   174\n",
      "100 9680k  100 9680k    0     0  2113k      0  0:00:04  0:00:04 --:--:-- 9008k\n",
      "[ Info: Downloading MNIST dataset\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   469  100   469    0     0   1104      0 --:--:-- --:--:-- --:--:--  1103\n",
      "100 28881  100 28881    0     0  30340      0 --:--:-- --:--:-- --:--:-- 30340\n",
      "[ Info: Downloading MNIST dataset\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   467  100   467    0     0   1123      0 --:--:-- --:--:-- --:--:--  1122\n",
      "100 1610k  100 1610k    0     0  1143k      0  0:00:01  0:00:01 --:--:-- 4686k\n",
      "[ Info: Downloading MNIST dataset\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   467  100   467    0     0   1130      0 --:--:-- --:--:-- --:--:--  1130\n",
      "100  4542  100  4542    0     0   5426      0 --:--:-- --:--:-- --:--:-- 21125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{String,Real}(\"accuracy_result\"=>0.0845667,\"training_time\"=>6.81843,\"loss_result\"=>2.31553 (tracked))"
     ]
    }
   ],
   "source": [
    "bash\"\"\"\n",
    "docker run edwardchalstrey/mlp_classifier:cpu\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then push to Docker Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/edwardchalstrey/mlp_classifier]\n",
      "0068878821ab: Preparing\n",
      "34e6dc24873a: Preparing\n",
      "6a425a0659f9: Preparing\n",
      "c16a6ae73666: Preparing\n",
      "0d6fbe8a52c0: Preparing\n",
      "371ecab57b6d: Preparing\n",
      "1b9b09744ade: Preparing\n",
      "9ad6d222ddc9: Preparing\n",
      "8c1e86448329: Preparing\n",
      "c797737f624c: Preparing\n",
      "37f8e8828549: Preparing\n",
      "36382f64a35d: Preparing\n",
      "5e57e1e34e26: Preparing\n",
      "889ba48cb5a1: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "36382f64a35d: Waiting\n",
      "5e57e1e34e26: Waiting\n",
      "889ba48cb5a1: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "371ecab57b6d: Waiting\n",
      "1b9b09744ade: Waiting\n",
      "9ad6d222ddc9: Waiting\n",
      "8c1e86448329: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "c797737f624c: Waiting\n",
      "37f8e8828549: Waiting\n",
      "0d6fbe8a52c0: Layer already exists\n",
      "c16a6ae73666: Layer already exists\n",
      "371ecab57b6d: Layer already exists\n",
      "1b9b09744ade: Layer already exists\n",
      "9ad6d222ddc9: Layer already exists\n",
      "8c1e86448329: Layer already exists\n",
      "34e6dc24873a: Pushed\n",
      "c797737f624c: Layer already exists\n",
      "37f8e8828549: Layer already exists\n",
      "6a425a0659f9: Pushed\n",
      "36382f64a35d: Layer already exists\n",
      "5e57e1e34e26: Layer already exists\n",
      "889ba48cb5a1: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "0068878821ab: Pushed\n",
      "cpu: digest: sha256:0a394b64ba529fd9640c9763e5302cf10c79db72da6151904cb8f987c1f0976c size: 4101\n"
     ]
    }
   ],
   "source": [
    "bash\"\"\"\n",
    "docker push edwardchalstrey/mlp_classifier:cpu\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a version of the code and Docker container where the model is running on NVIDIA GPU with CUDA\n",
    "---\n",
    "\n",
    "To run in a Docker container on a machine with NVIDIA GPUs, the following steps must be taken:\n",
    "\n",
    "1. Follow the [installation instructions for CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html) (can download from [here](https://developer.nvidia.com/cuda-toolkit)), then the [post-installation instructions](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#mandatory-post) and make sure you have a version of Docker that [is supported](https://github.com/NVIDIA/nvidia-docker/wiki/Frequently-Asked-Questions#which-docker-packages-are-supported)\n",
    "2. Install [nvidia-docker](https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0)#installing-version-20)\n",
    "3. Run the container with nvidia-docker e.g. ```nvidia-docker run edwardchalstrey/mlp_classifier:gpu```\n",
    "\n",
    "### First lets un-comment CuArrays in the classifier\n",
    "\n",
    "This version, where we are ```using CuArrays``` can't be run without NVIDIA GPU support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module MLPClassifier.\n",
      "┌ Info: Precompiling CuArrays [3a865a2d-5b23-5a0f-bc46-62713ec82fae]\n",
      "└ @ Base loading.jl:1192\n",
      "ERROR: LoadError: LoadError: UndefVarError: CUBLAS not defined\n",
      "Stacktrace:\n",
      " [1] top-level scope at none:0 (repeats 2 times)\n",
      " [2] include at ./boot.jl:317 [inlined]\n",
      " [3] include_relative(::Module, ::String) at ./loading.jl:1044\n",
      " [4] include at ./sysimg.jl:29 [inlined]\n",
      " [5] include(::String) at /Users/echalstrey/.julia/packages/CuArrays/PD3UJ/src/CuArrays.jl:3\n",
      " [6] top-level scope at none:0\n",
      " [7] include at ./boot.jl:317 [inlined]\n",
      " [8] include_relative(::Module, ::String) at ./loading.jl:1044\n",
      " [9] include(::Module, ::String) at ./sysimg.jl:29\n",
      " [10] top-level scope at none:2\n",
      " [11] eval at ./boot.jl:319 [inlined]\n",
      " [12] eval(::Expr) at ./client.jl:393\n",
      " [13] top-level scope at ./none:3\n",
      "in expression starting at /Users/echalstrey/.julia/packages/CuArrays/PD3UJ/src/deprecated.jl:5\n",
      "in expression starting at /Users/echalstrey/.julia/packages/CuArrays/PD3UJ/src/CuArrays.jl:53\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile CuArrays [3a865a2d-5b23-5a0f-bc46-62713ec82fae] to /Users/echalstrey/.julia/compiled/v1.0/CuArrays/7YFE0.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile CuArrays [3a865a2d-5b23-5a0f-bc46-62713ec82fae] to /Users/echalstrey/.julia/compiled/v1.0/CuArrays/7YFE0.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1203",
      " [3] _require(::Base.PkgId) at ./loading.jl:960",
      " [4] require(::Base.PkgId) at ./loading.jl:858",
      " [5] require(::Module, ::Symbol) at ./loading.jl:853"
     ]
    }
   ],
   "source": [
    "module MLPClassifier\n",
    "\n",
    "    using Flux, Statistics\n",
    "    using Flux: onehotbatch, onecold, crossentropy, throttle # Flux is a neural network machine learning library, rivals TensorFlow\n",
    "    using Base.Iterators: repeated\n",
    "    using CuArrays\n",
    "\n",
    "    function create_model()\n",
    "        \n",
    "        m = Chain(Dense(28^2, 32, relu), Dense(32, 10), softmax) |> gpu\n",
    "        return m\n",
    "    \n",
    "    end\n",
    "\n",
    "    function benchmark_model(m, imgs, labels; epochs=3, dataset_n=1)\n",
    "\n",
    "        # Stack images into one large batch. Concatenates along 2 dimensions\n",
    "        X = hcat(float.(reshape.(imgs, :))...) |> gpu # pipe to gpu, this does nothing when CuArrays is not loaded\n",
    "\n",
    "        # One-hot-encode the labels\n",
    "        Y = onehotbatch(labels, 0:9) |> gpu     \n",
    "\n",
    "        loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "        accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "        # Create a dataset by repeating dataset_n times\n",
    "        dataset = repeated((X, Y), dataset_n)\n",
    "\n",
    "        # accuracy() computes the fraction of correctly predicted outcomes in outputs (Y) according to the given true targets (X).\n",
    "        # loss() the loss function gives a number which an optimization would seek to minimize\n",
    "\n",
    "        opt = ADAM()\n",
    "\n",
    "        # Train the multi-layer-perceptron:\n",
    "        start_time = time_ns()\n",
    "        for i = 1:epochs\n",
    "            Flux.train!(loss, params(m), dataset, opt)\n",
    "        end\n",
    "        end_time = time_ns()\n",
    "\n",
    "        # Results\n",
    "        training_time = (end_time - start_time)/1.0e9 #seconds\n",
    "        loss_result = loss(X, Y)\n",
    "        accuracy_result = accuracy(X, Y)\n",
    "\n",
    "        # Create results dictionary and print to output\n",
    "        output_dict = Dict(\"training_time\" => training_time, \"loss_result\" => loss_result, \"accuracy_result\" => accuracy_result)\n",
    "        return output_dict\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"mlp.jl\", In[IJulia.n-1]) # write the previously run cell to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-comment CuArrays in the Dockerfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"nvidia\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"nvidia\" after end of expression",
      ""
     ]
    }
   ],
   "source": [
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN  apt-get update \\\n",
    "  && apt-get install -y wget \\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "\n",
    "RUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\n",
    "RUN tar xvfa julia-1.0.0-linux-x86_64.tar.gz\n",
    "\n",
    "COPY mlp.jl /julia-1.0.0/bin/mlp.jl\n",
    "COPY iterate_benchmarks.jl /julia-1.0.0/bin/iterate_benchmarks.jl\n",
    "\n",
    "WORKDIR /julia-1.0.0/bin\n",
    "RUN ./julia -e 'using Pkg; Pkg.add(\"Flux\")'\n",
    "RUN ./julia -e 'using Pkg; Pkg.add(\"CuArrays\")'\n",
    "CMD ./julia iterate_benchmarks.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"Dockerfile\", In[IJulia.n-1]) # write the previously run cell to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !! Uh oh !! - We have an issue building this version\n",
    "\n",
    "We are unable to build this, even on a machine with the CUDA toolkit installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  163.8kB\n",
      "Step 1/12 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> f722eab170b7\n",
      "Step 2/12 : RUN  apt-get update   && apt-get install -y wget   && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 6c8df59a2db7\n",
      "Step 3/12 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 52daa6d5e08f\n",
      "Step 4/12 : RUN apt-get -y install curl\n",
      " ---> Using cache\n",
      " ---> f4b4ff210f19\n",
      "Step 5/12 : RUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\n",
      " ---> Using cache\n",
      " ---> 9b5d7c5c2cfd\n",
      "Step 6/12 : RUN tar xvfa julia-1.0.0-linux-x86_64.tar.gz\n",
      " ---> Using cache\n",
      " ---> 71f8c0aebc04\n",
      "Step 7/12 : COPY mlp.jl /julia-1.0.0/bin/mlp.jl\n",
      " ---> Using cache\n",
      " ---> baa9ce743d0f\n",
      "Step 8/12 : COPY iterate_benchmarks.jl /julia-1.0.0/bin/iterate_benchmarks.jl\n",
      " ---> Using cache\n",
      " ---> 1169e455d3c2\n",
      "Step 9/12 : WORKDIR /julia-1.0.0/bin\n",
      " ---> Using cache\n",
      " ---> 414ab46ba9bb\n",
      "Step 10/12 : RUN ./julia -e 'using Pkg; Pkg.add(\"Flux\")'\n",
      " ---> Using cache\n",
      " ---> 766bb6f8905f\n",
      "Step 11/12 : RUN ./julia -e 'using Pkg; Pkg.add(\"CuArrays\")'\n",
      " ---> Using cache\n",
      " ---> 6385a5678d4a\n",
      "Step 12/12 : CMD ./julia iterate_benchmarks.jl\n",
      " ---> Using cache\n",
      " ---> 2e4e1a69a000\n",
      "Successfully built 2e4e1a69a000\n",
      "Successfully tagged edwardchalstrey/mlp_classifier:gpu\n"
     ]
    }
   ],
   "source": [
    "bash\"\"\"\n",
    "docker build -t edwardchalstrey/mlp_classifier:gpu .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un-comment below to push when build works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash\"\"\"\n",
    "# docker push edwardchalstrey/mlp_classifier:gpu\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attempting to run this version on a system with CUDA installed, I get the following errors:\n",
    "\n",
    "1. ```ERROR: LoadError: LoadError: UndefVarError: CUBLAS not defined```\n",
    "2. ```ERROR: LoadError: LoadError: Failed to precompile CuArrays```\n",
    "\n",
    "[On further investigation](https://discourse.julialang.org/t/trouble-building-docker-container-with-cuarrays/22347), it appears that delayed package installation is the only option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative solution, delayed package installation:\n",
    "\n",
    "This one works by running the container, then installing Flux and CuArrays, then running the benchmarks as follows:\n",
    "\n",
    "1. ```sudo docker run --runtime=nvidia -it edwardchalstrey/juliagpu /bin/bash```\n",
    "2. In the container do:\n",
    "    - ```./julia -e 'using Pkg; Pkg.add(\"Flux\")'```\n",
    "    - ```./julia -e 'using Pkg; Pkg.add(\"CuArrays\")'```\n",
    "    - ```./julia iterate_benchmarks.jl 1 1 1``` (subsituting different integer arguments here)\n",
    "    \n",
    "I've set this up as a separate container called ```edwardchalstrey/juliagpu```.\n",
    "\n",
    "Doing it this way means that ```CuArrays``` is installed correctly.\n",
    "\n",
    "Revise the Dockerfile so we don't attempt to install the Julia packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"nvidia\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"nvidia\" after end of expression",
      ""
     ]
    }
   ],
   "source": [
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN  apt-get update \\\n",
    "  && apt-get install -y wget \\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "\n",
    "RUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\n",
    "RUN tar xvfa julia-1.0.0-linux-x86_64.tar.gz\n",
    "\n",
    "COPY mlp.jl /julia-1.0.0/bin/mlp.jl\n",
    "COPY iterate_benchmarks.jl /julia-1.0.0/bin/iterate_benchmarks.jl\n",
    "\n",
    "WORKDIR /julia-1.0.0/bin\n",
    "CMD [\"./julia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"Dockerfile\", In[IJulia.n-1]) # write the previously run cell to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and push this alternate container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  163.3kB\n",
      "Step 1/10 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> f722eab170b7\n",
      "Step 2/10 : RUN  apt-get update   && apt-get install -y wget   && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 6c8df59a2db7\n",
      "Step 3/10 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 52daa6d5e08f\n",
      "Step 4/10 : RUN apt-get -y install curl\n",
      " ---> Using cache\n",
      " ---> f4b4ff210f19\n",
      "Step 5/10 : RUN wget https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\n",
      " ---> Using cache\n",
      " ---> 9b5d7c5c2cfd\n",
      "Step 6/10 : RUN tar xvfa julia-1.0.0-linux-x86_64.tar.gz\n",
      " ---> Using cache\n",
      " ---> 71f8c0aebc04\n",
      "Step 7/10 : COPY mlp.jl /julia-1.0.0/bin/mlp.jl\n",
      " ---> Using cache\n",
      " ---> baa9ce743d0f\n",
      "Step 8/10 : COPY iterate_benchmarks.jl /julia-1.0.0/bin/iterate_benchmarks.jl\n",
      " ---> Using cache\n",
      " ---> 1169e455d3c2\n",
      "Step 9/10 : WORKDIR /julia-1.0.0/bin\n",
      " ---> Using cache\n",
      " ---> 414ab46ba9bb\n",
      "Step 10/10 : CMD [\"./julia\"]\n",
      " ---> Using cache\n",
      " ---> dd87a2f49058\n",
      "Successfully built dd87a2f49058\n",
      "Successfully tagged edwardchalstrey/juliagpu:latest\n"
     ]
    }
   ],
   "source": [
    "bash\"\"\"\n",
    "docker build -t edwardchalstrey/juliagpu .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/edwardchalstrey/juliagpu]\n",
      "b3076873de1d: Preparing\n",
      "492804de3e77: Preparing\n",
      "c16a6ae73666: Preparing\n",
      "0d6fbe8a52c0: Preparing\n",
      "371ecab57b6d: Preparing\n",
      "1b9b09744ade: Preparing\n",
      "9ad6d222ddc9: Preparing\n",
      "8c1e86448329: Preparing\n",
      "c797737f624c: Preparing\n",
      "37f8e8828549: Preparing\n",
      "36382f64a35d: Preparing\n",
      "5e57e1e34e26: Preparing\n",
      "889ba48cb5a1: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "9ad6d222ddc9: Waiting\n",
      "5e57e1e34e26: Waiting\n",
      "889ba48cb5a1: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "8c1e86448329: Waiting\n",
      "c797737f624c: Waiting\n",
      "36382f64a35d: Waiting\n",
      "1b9b09744ade: Waiting\n",
      "37f8e8828549: Waiting\n",
      "c16a6ae73666: Layer already exists\n",
      "0d6fbe8a52c0: Layer already exists\n",
      "371ecab57b6d: Layer already exists\n",
      "492804de3e77: Layer already exists\n",
      "b3076873de1d: Layer already exists\n",
      "1b9b09744ade: Layer already exists\n",
      "9ad6d222ddc9: Layer already exists\n",
      "8c1e86448329: Layer already exists\n",
      "c797737f624c: Layer already exists\n",
      "37f8e8828549: Layer already exists\n",
      "5e57e1e34e26: Layer already exists\n",
      "36382f64a35d: Layer already exists\n",
      "889ba48cb5a1: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "latest: digest: sha256:9d94e013280dfbc1fa3083f119da3dccede70a9e81eb939914736b8db87c22ff size: 3889\n",
      "31db70909fae: Preparing\n",
      "575becc17c68: Preparing\n",
      "c16a6ae73666: Preparing\n",
      "0d6fbe8a52c0: Preparing\n",
      "371ecab57b6d: Preparing\n",
      "1b9b09744ade: Preparing\n",
      "9ad6d222ddc9: Preparing\n",
      "8c1e86448329: Preparing\n",
      "c797737f624c: Preparing\n",
      "37f8e8828549: Preparing\n",
      "36382f64a35d: Preparing\n",
      "5e57e1e34e26: Preparing\n",
      "889ba48cb5a1: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "37f8e8828549: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "36382f64a35d: Waiting\n",
      "5e57e1e34e26: Waiting\n",
      "889ba48cb5a1: Waiting\n",
      "c16a6ae73666: Layer already exists\n",
      "0d6fbe8a52c0: Layer already exists\n",
      "371ecab57b6d: Layer already exists\n",
      "1b9b09744ade: Layer already exists\n",
      "9ad6d222ddc9: Layer already exists\n",
      "8c1e86448329: Layer already exists\n",
      "889ba48cb5a1: Layer already exists\n",
      "37f8e8828549: Layer already exists\n",
      "36382f64a35d: Layer already exists\n",
      "5e57e1e34e26: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "c797737f624c: Layer already exists\n",
      "575becc17c68: Layer already exists\n",
      "31db70909fae: Layer already exists\n",
      "noevalcb: digest: sha256:181766058c6b7d820856841ba08f13d4bb38d2f7c15e8c9821fdee002996c524 size: 3889\n"
     ]
    }
   ],
   "source": [
    "bash\"\"\"\n",
    "docker push edwardchalstrey/juliagpu\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "----\n",
    "\n",
    "I can now run the benchmarks on any computing platform with the CUDA toolkit and NVIDIA-Docker installed (the CPU version on any platform with Docker).\n",
    "\n",
    "**Platform:**\n",
    "\n",
    "1. Azure VM 1: Standard NC6 (6 vcpus, 56 GB memory); Ubuntu 18.04; CUDA 9.0\n",
    "\n",
    "**Benchmarks:**\n",
    "1. Benchmark repeats = 10; Epochs = 10; Dataset size = 1\n",
    "2. Benchmark repeats = 10; Epochs = 20; Dataset size = 1\n",
    "3. Benchmark repeats = 10; Epochs = 50; Dataset size = 1\n",
    "4. Benchmark repeats = 10; Epochs = 200; Dataset size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Benchmark</th><th>Accuracy</th><th>Loss</th><th>trainingTimeSeconds</th></tr><tr><th></th><th>String</th><th>Any</th><th>Float64</th><th>Any</th></tr></thead><tbody><p>8 rows × 4 columns</p><tr><th>1</th><td>Azure VM 1; CPU; Benchmark 1</td><td>0.880783</td><td>0.4649</td><td>3.54387</td></tr><tr><th>2</th><td>Azure VM 1; GPU; Benchmark 1</td><td>0.876758</td><td>0.480444</td><td>0.255519</td></tr><tr><th>3</th><td>Azure VM 1; CPU; Benchmark 2</td><td>0.925517</td><td>0.267284</td><td>9.0776</td></tr><tr><th>4</th><td>Azure VM 1; GPU; Benchmark 2</td><td>0.927475</td><td>0.258824</td><td>0.512827</td></tr><tr><th>5</th><td>Azure VM 1; CPU; Benchmark 3</td><td>0.962342</td><td>0.131131</td><td>18.0053</td></tr><tr><th>6</th><td>Azure VM 1; GPU; Benchmark 3</td><td>0.960758</td><td>0.141972</td><td>2.46613</td></tr><tr><th>7</th><td>Azure VM 1; CPU; Benchmark 4</td><td>-</td><td>NaN</td><td>-</td></tr><tr><th>8</th><td>Azure VM 1; GPU; Benchmark 4</td><td>0.997875</td><td>0.0156178</td><td>11.1517</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Benchmark & Accuracy & Loss & trainingTimeSeconds\\\\\n",
       "\t\\hline\n",
       "\t& String & Any & Float64 & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & Azure VM 1; CPU; Benchmark 1 & 0.880783 & 0.4649 & 3.54387 \\\\\n",
       "\t2 & Azure VM 1; GPU; Benchmark 1 & 0.876758 & 0.480444 & 0.255519 \\\\\n",
       "\t3 & Azure VM 1; CPU; Benchmark 2 & 0.925517 & 0.267284 & 9.0776 \\\\\n",
       "\t4 & Azure VM 1; GPU; Benchmark 2 & 0.927475 & 0.258824 & 0.512827 \\\\\n",
       "\t5 & Azure VM 1; CPU; Benchmark 3 & 0.962342 & 0.131131 & 18.0053 \\\\\n",
       "\t6 & Azure VM 1; GPU; Benchmark 3 & 0.960758 & 0.141972 & 2.46613 \\\\\n",
       "\t7 & Azure VM 1; CPU; Benchmark 4 & - & NaN & - \\\\\n",
       "\t8 & Azure VM 1; GPU; Benchmark 4 & 0.997875 & 0.0156178 & 11.1517 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "8×4 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ Benchmark                    │ Accuracy │ Loss      │\n",
       "│     │ \u001b[90mString\u001b[39m                       │ \u001b[90mAny\u001b[39m      │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼──────────────────────────────┼──────────┼───────────┤\n",
       "│ 1   │ Azure VM 1; CPU; Benchmark 1 │ 0.880783 │ 0.4649    │\n",
       "│ 2   │ Azure VM 1; GPU; Benchmark 1 │ 0.876758 │ 0.480444  │\n",
       "│ 3   │ Azure VM 1; CPU; Benchmark 2 │ 0.925517 │ 0.267284  │\n",
       "│ 4   │ Azure VM 1; GPU; Benchmark 2 │ 0.927475 │ 0.258824  │\n",
       "│ 5   │ Azure VM 1; CPU; Benchmark 3 │ 0.962342 │ 0.131131  │\n",
       "│ 6   │ Azure VM 1; GPU; Benchmark 3 │ 0.960758 │ 0.141972  │\n",
       "│ 7   │ Azure VM 1; CPU; Benchmark 4 │ -        │ NaN       │\n",
       "│ 8   │ Azure VM 1; GPU; Benchmark 4 │ 0.997875 │ 0.0156178 │"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_results = [0.4649, 0.480444, 0.267284, 0.258824, 0.131131, 0.141972, NaN, 0.0156178]\n",
    "accuracy_results = [0.880783, 0.876758, 0.925517, 0.927475, 0.962342, 0.960758, -, 0.997875]\n",
    "training_times = [3.54387, 0.255519, 9.0776, 0.512827, 18.0053, 2.46613, -, 11.1517]\n",
    "benchmarks = [\"Azure VM 1; CPU; Benchmark 1\", \"Azure VM 1; GPU; Benchmark 1\", \"Azure VM 1; CPU; Benchmark 2\", \"Azure VM 1; GPU; Benchmark 2\", \"Azure VM 1; CPU; Benchmark 3\", \"Azure VM 1; GPU; Benchmark 3\", \"Azure VM 1; CPU; Benchmark 4\", \"Azure VM 1; GPU; Benchmark 4\"]\n",
    "df = DataFrame(Benchmark = benchmarks, Accuracy = accuracy_results, Loss = loss_results, trainingTimeSeconds = training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, GPU usage offers speed improvement relative to CPU for training the neural network. \n",
    "\n",
    "### Next\n",
    "\n",
    "Azure VM 1; CPU; Benchmark 4 threw an error: ```ERROR: LoadError: Loss is NaN``` - investigate further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
